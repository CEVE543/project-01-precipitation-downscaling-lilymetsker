{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Precipitation Downscaling Project\n",
        "format:\n",
        "  html:\n",
        "    toc-depth: 3\n",
        "  docx:\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    fig-format: png\n",
        "date: 2023-11-2\n",
        "author: Lily Metsker (lm88)\n",
        "echo: false\n",
        "number-sections: true\n",
        "code-annotations: hover\n",
        "kind: Project\n",
        "Module: '2'\n",
        "categories:\n",
        "  - Module 2\n",
        "  - Project\n",
        "---"
      ],
      "id": "3b4078d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Executive Summary:\n",
        "\n",
        "The goal of this project is to predict precipitation in Texas at time point “t+1” given temperature at time “t”. This analysis uses CPC gauge-based gridded daily precipitation and daily temperature data over roughly the area of Texas from the years 2000 to 2009 to train two different predictive models. Both models applied a principal component analysis (PCA) to downscale the high dimensional temperature data, and then fit models on the selected principal components. In the first approach, K-nearest neighbors (KNN) was applied to the principal components to predict precipitation based on a subsetted testing set of temperature data to allow for comparison to actual values. In the second approach, a linear regression model was applied to the first principal component only to predict precipitation corresponding to the same testing temperature dataset. \n",
        "\n",
        "In order to validate the fit of the models, mean squared error, mean absolute error, and residuals were calculated. These metrics were also used to compare the performance between the two models. Though upon visual inspection PCA-KNN appears to predict precipitation trends closer to observed values, the PCA-KNN approach exhibited a higher mean squared error and mean absolute error than the PCA-linear regression model despite a lower average residual value. Higher mean absolute error and mean squared error indicates that the PCA-KNN model actually performs worse than the PCA-linear regression model, likely due to large variations and inaccuracies in extreme values. The PCA-linear regression model, on the other hand, exhibits a conservative, “dreary” prediction across all time points, which leads to lower error overall when dealing with extremes.\n",
        "\n",
        "Methods\n",
        "\n",
        "Data Management/Preprocessing\n",
        "The original precipitation data was subsetted to only include the years 2000 to 2009 to correspond to the selected temperature data timeframe. Temperature data was subsetted to match the space occupied by the precipitation data and cover roughly the area of Texas. Latitude and longitude were adjusted to ensure consistent formatting across the datasets. To predict on precipitation at time t+1, the precipitation time points used in the analysis were shifted one day from the temperature data time points. Precipitation and temperature data were then split to create training and testing sets, with years 2000 to 2007 included in training and the rest allocated to testing. Temperature data was preprocessed by calculating the mean climatology and obtaining the anomalies rather than working with raw temperatures to better account for seasonal variation.\n",
        "\n",
        "1. Setup\n",
        "\n",
        "1.1 Load Packages\n"
      ],
      "id": "4f465e11"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using Dates\n",
        "using MultivariateStats\n",
        "using Plots\n",
        "using NCDatasets\n",
        "using StatsBase\n",
        "using Unitful\n",
        "using Distances\n",
        "using GLM\n",
        "using NetCDF\n",
        "using DataFrames"
      ],
      "id": "b7e5d2f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Data\n",
        "\n",
        "2.1 Precipitation\n",
        "2.1.1 Load data\n"
      ],
      "id": "73d5da96"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#load precip data from NCDataset, this precip is over the area of Texas\n",
        "precip_ds = NCDataset(\"data/raw/precip_tx.nc\")\n",
        "#define time, longitude, latitude, and precip as variables. precip is a matrix and time, lon, and lat are vectors\n",
        "precip_time = precip_ds[\"time\"][:]\n",
        "precip_lon = precip_ds[\"lon\"][:]\n",
        "precip_lat = precip_ds[\"lat\"][:]\n",
        "precip = precip_ds[\"precip\"][:,:,:]"
      ],
      "id": "d501f8a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.1.2 Close precip dataset\n"
      ],
      "id": "51e0e926"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "close(precip_ds) "
      ],
      "id": "2dbaa898",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.1.3 Filter data\n"
      ],
      "id": "89f87adf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#filter precip to only include 2000-2009\n",
        "t_start = 2000\n",
        "t_end = 2009\n",
        "\n",
        "start_ind = findfirst(date -> year(date) >= t_start, precip_time)\n",
        "end_ind = findlast(date -> year(date) <= t_end, precip_time)\n",
        "precip = precip[:,:, start_ind:end_ind]\n",
        "precip_time = precip_time[start_ind:end_ind]"
      ],
      "id": "ae190c05",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.1.4 Subset data\n"
      ],
      "id": "e77973a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#subset precip to time range t+1\n",
        "t_start = Dates.DateTime(2000, 1, 2)\n",
        "t_end = Dates.DateTime(2009, 12, 31)\n",
        "\n",
        "#create index for filtering \n",
        "\n",
        "precip_indices = t_start .<= precip_time .<= t_end\n",
        "\n",
        "precip = precip[:, :, precip_indices]\n",
        "precip_time_plus = precip_time[precip_indices]"
      ],
      "id": "bcf0ef15",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.1.5 Reverse latitude\n"
      ],
      "id": "370274d7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#dims 2 is telling to reverse along the second dimension (latitude)\n",
        "precip_lat = reverse(precip_lat)\n",
        "precip = reverse(precip;dims=2)"
      ],
      "id": "80ec14a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.1.6 Convert lon to lon1 format\n"
      ],
      "id": "db9fb14b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Convert long3 to long1 format (source: https://confluence.ecmwf.int/pages/viewpage.action?pageId=149337515)\n",
        "function convert_longitude(longitude)\n",
        "    lon1 = ifelse(longitude > 180, longitude - 360, longitude)\n",
        "    return lon1\n",
        "end\n",
        "\n",
        "precip_lon = convert_longitude.(precip_lon)"
      ],
      "id": "fc6aecde",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.2 Temperature\n",
        "\n",
        "2.2.1 Load data\n",
        "#(move to get_data.jl file)?\n"
      ],
      "id": "e6919d46"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#This code block was written by Chatgpt to resample hourly temperature data to daily temperature data\n",
        "\n",
        "# Write a function to convert hourly temperature to daily average\n",
        "function resample_to_daily_average(temp, temp_time)\n",
        "\n",
        "    #use floor to extract the date from the time, save as date_vector\n",
        "    date_vector = floor.(temp_time, Dates.Day)\n",
        "    #find all unique dates in the date_vector, save as unique_dates\n",
        "    unique_dates = unique(date_vector)\n",
        "\n",
        "    # Find the size of the temperature array, save as lon_points and lat_points\n",
        "    lon_points, lat_points, _ = size(temp)\n",
        "\n",
        "    # Create an empty array to store daily temperature averages\n",
        "    daily_temps = []\n",
        "\n",
        "    # Calculate daily mean by grouping unique dates\n",
        "    for date in unique_dates\n",
        "        # Find indices of all time points under a unique date\n",
        "        indices = findall(date_vector .== date)\n",
        "        \n",
        "        # Calculate daily mean for each lonxlat point\n",
        "        daily_mean = mean(temp[:, :, indices], dims=3)[:, :, 1]\n",
        "        \n",
        "        # Add daily mean to the empty array\n",
        "        push!(daily_temps, daily_mean)\n",
        "    end\n",
        "\n",
        "    # Concatenate daily means into a 3D array along the 3rd dimension\n",
        "    daily_temps = cat(daily_temps..., dims=3)\n",
        "\n",
        "    return daily_temps\n",
        "end\n",
        "\n",
        "#Write a function to call and process each year of temperature data\n",
        "function process_year(data_path)\n",
        "    # Extract year from filename, all files follow a common path structure\n",
        "    match_result = match(r\"2m_temperature_(\\d{4})\\.nc\", data_path)\n",
        "    #save individual years as string\n",
        "    year_str = match_result.captures[1]\n",
        "    #save as variable of integers\n",
        "    year = parse(Int, year_str)\n",
        "\n",
        "    # Load year's data, all files follow common data_path\n",
        "    temp_dataset = NCDataset(data_path)\n",
        "\n",
        "    # Save lon, lat, time, and temperature as variables\n",
        "    longitude = temp_dataset[\"longitude\"][:]\n",
        "    latitude = temp_dataset[\"latitude\"][:]\n",
        "    time = temp_dataset[\"time\"][:]\n",
        "    t2m = temp_dataset[\"t2m\"][:, :, :]\n",
        "\n",
        "    #save time as temp_time\n",
        "    temp_time = time\n",
        "\n",
        "    # Resample temperature data to daily averages\n",
        "    daily_temps_result = resample_to_daily_average(t2m, temp_time)\n",
        "\n",
        "    return year, daily_temps_result\n",
        "end\n",
        "\n",
        "# Paths to your data files for each year\n",
        "data_paths = [\n",
        "    \"data/raw/2m_temperature_2000.nc\",\n",
        "    \"data/raw/2m_temperature_2001.nc\",\n",
        "    \"data/raw/2m_temperature_2002.nc\",\n",
        "    \"data/raw/2m_temperature_2003.nc\",\n",
        "    \"data/raw/2m_temperature_2004.nc\",\n",
        "    \"data/raw/2m_temperature_2005.nc\",\n",
        "    \"data/raw/2m_temperature_2006.nc\",\n",
        "    \"data/raw/2m_temperature_2007.nc\",\n",
        "    \"data/raw/2m_temperature_2008.nc\",\n",
        "    \"data/raw/2m_temperature_2009.nc\"\n",
        "]\n",
        "\n",
        "# Process each year and combine the results\n",
        "all_years_temps = Dict(process_year(path) for path in data_paths if process_year(path) !== nothing)"
      ],
      "id": "396879f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.2.2 Combine\n"
      ],
      "id": "ef26dc1b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#combine all years into one array\n",
        "#call all years and save each as a matrix with lon = 66, lat = 27, and time in days, 365 for non-leap years and 366 for leap years\n",
        "temp_2000 = reshape(all_years_temps[2000], 66, 27, 366)\n",
        "temp_2001 = reshape(all_years_temps[2001], 66, 27, 365)\n",
        "temp_2002 = reshape(all_years_temps[2002], 66, 27, 365)\n",
        "temp_2003 = reshape(all_years_temps[2003], 66, 27, 365)\n",
        "temp_2004 = reshape(all_years_temps[2004], 66, 27, 366)\n",
        "temp_2005 = reshape(all_years_temps[2005], 66, 27, 365)\n",
        "temp_2006 = reshape(all_years_temps[2006], 66, 27, 365)\n",
        "temp_2007 = reshape(all_years_temps[2007], 66, 27, 365)\n",
        "temp_2008 = reshape(all_years_temps[2008], 66, 27, 366)\n",
        "temp_2009 = reshape(all_years_temps[2009], 66, 27, 365)\n",
        "\n",
        "#combine \n",
        "temp = cat(temp_2000, temp_2001, temp_2002, temp_2003, temp_2004, temp_2005, temp_2006, temp_2007, temp_2008, temp_2009, dims=3)"
      ],
      "id": "83db4095",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.2.3 Save lon, lat, time, and temp variables\n"
      ],
      "id": "f9914934"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Having trouble writing variable using same form of calling above, used data_dict instead but not optimal\n",
        "\n",
        "#save data_dict for 2000\n",
        "data_dict = open_mfdataset([\"data/raw/2m_temperature_2000.nc\"], \"t2m\")\n",
        "\n",
        "#define lon and lat based on year 2000 (should be the same for all years) and temp_time as precip_time (should be the same)\n",
        "temp_lon = data_dict[\"longitude\"][:]\n",
        "temp_lat = data_dict[\"latitude\"][:]\n",
        "temp_time = precip_time"
      ],
      "id": "c3a41aa8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.2.4 Flip the temperature latitude\n"
      ],
      "id": "35121084"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp_lat = reverse(temp_lat)\n",
        "temp = reverse(temp;dims=2)"
      ],
      "id": "28d5f0dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.2.5 Subset temperature to area of Texas instead of US\n"
      ],
      "id": "651f418a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define longitude and latitude ranges for filtering based on precip data which is already filtered to Texas\n",
        "lon_min = minimum(precip_lon)\n",
        "lon_max = maximum(precip_lon)\n",
        "lat_min = minimum(precip_lat)\n",
        "lat_max = maximum(precip_lat)\n",
        "\n",
        "# Create masks for latitude and longitude based on specified ranges\n",
        "lat_mask = (lat_min .<= temp_lat .<= lat_max)\n",
        "lon_mask = (lon_min .<= temp_lon .<= lon_max)\n",
        "\n",
        "# Convert BitVector to Vector{Int} using findall\n",
        "lat_indices = findall(lat_mask)\n",
        "lon_indices = findall(lon_mask)\n",
        "\n",
        "# Update latitude and longitude data variables\n",
        "temp_lat = temp_lat[lat_indices]\n",
        "temp_lon = temp_lon[lon_indices]\n",
        "\n",
        "# Subset temperature data based on latitude and longitude indices\n",
        "temp = temp[lon_indices, lat_indices, :]"
      ],
      "id": "18bbfe30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.2.6 Subset temperature time\n"
      ],
      "id": "422eec80"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#subset temperature to time range t \n",
        "t_start = Dates.DateTime(2000, 1, 1)\n",
        "t_end = Dates.DateTime(2009, 12, 30)\n",
        "\n",
        "#Create index for filtering\n",
        "temp_indices = t_start .<= temp_time .<= t_end\n",
        "\n",
        "temp = temp[:, :, temp_indices]\n",
        "\n",
        "temp_time = temp_time[temp_indices]"
      ],
      "id": "0d2b955b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.3 Split data into training and testing sets\n"
      ],
      "id": "5bc23bcd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#2000-2007 for training, 2008-2009 for testing\n",
        "#Define start and end times\n",
        "temp_t_start = Dates.DateTime(2000, 1, 1)\n",
        "temp_t_end = Dates.DateTime(2007, 12, 30)\n",
        "\n",
        "# Create indices for temperature\n",
        "temp_train_indices = temp_t_start .<= temp_time .<= temp_t_end\n",
        "temp_test_indices = temp_time .> temp_t_end\n",
        "\n",
        "#Subset temperature data based on indices\n",
        "temp_train = temp[:, :, temp_train_indices]\n",
        "temp_test = temp[:, :, temp_test_indices]\n",
        "\n",
        "#Subset temperature time based on indices\n",
        "time_train = filter(date -> temp_t_start <= date <= temp_t_end, temp_time)\n",
        "time_test = filter(date -> temp_t_end <= date , temp_time)\n",
        "\n",
        "#Create indices for precipitation\n",
        "precip_t_start = Dates.DateTime(2000, 1, 2)\n",
        "precip_t_end = Dates.DateTime(2007, 12, 31)\n",
        "\n",
        "#Subset precipitation data based on indices\n",
        "precip_train_indices = precip_t_start .<= precip_time_plus .<= precip_t_end\n",
        "precip_test_indices = precip_time_plus .> precip_t_end\n",
        "\n",
        "#Subset precipitation data based on indices\n",
        "precip_train = precip[:, :, precip_train_indices]\n",
        "precip_test = precip[:, :, precip_test_indices]\n"
      ],
      "id": "63713754",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.4 Preprocessing\n",
        "\n",
        "2.4.1 Preprocess function\n"
      ],
      "id": "9f4a32c5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "function preprocess(temp::Array{T, 3}, temp_ref::Array{T,3}) where T\n",
        "  #we use temp_ref because we want the climatology to be the same between the test and train datasets!\n",
        "           #name lon, lat, and time as the dimensions of the temp input matrix\n",
        "           lon, lat, time = size(temp)\n",
        "           #find the climatology, dims=3 says take along the 3rd dimension (time)\n",
        "           climatology = mean(temp_ref, dims=3)\n",
        "           temp_anom = temp .- climatology\n",
        "           #reshape the data by multiplying lonxlat to a 2D matrix\n",
        "           temp_anom = reshape(temp_anom, (lon * lat, time))\n",
        "           #return\n",
        "           return temp_anom\n",
        "       end"
      ],
      "id": "1c008311",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.4.2 Preprocess temperature\n"
      ],
      "id": "a8dad84e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "temp_train_proc = preprocess(temp_train, temp_train)\n",
        "temp_test_proc = preprocess(temp_test, temp_train)"
      ],
      "id": "cce7a600",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.4.3 Reshape precip\n"
      ],
      "id": "462c9fa2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#reshape precip_train and precip_test to 2D matrices\n",
        "precip_train_reshape = reshape(precip_train, (24 * 24, 2921))\n",
        "precip_test_reshape = reshape(precip_test, (24 * 24, 731))"
      ],
      "id": "665b81fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Principal Component Analysis\n",
        "3.1 Fit PCA model\n"
      ],
      "id": "cc46272e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pca_model = fit(PCA, temp_train_proc; maxoutdim=25);"
      ],
      "id": "890cd304",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.2 Plot variance to determine number of PCs to keep\n"
      ],
      "id": "f7310688"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#plot the variance explained\n",
        "var_explained = plot(\n",
        "    principalvars(pca_model) / var(pca_model),\n",
        "    xlabel=\"PC\",\n",
        "    ylabel=\"Fraction of variance explained\",\n",
        "    label=false,\n",
        "    title=\"Variance Explained by PCs\"\n",
        ")\n",
        "#plot the cumulative variance explained (cdf)\n",
        "cum_var_explained = plot(\n",
        "    cumsum(principalvars(pca_model)) / var(pca_model);\n",
        "    xlabel=\"PC\",\n",
        "    ylabel=\"Fraction of variance explained\",\n",
        "    label=false,\n",
        "    title=\"Cumulative Variance Explained\"\n",
        ")\n",
        "#Plot \n",
        "plot(var_explained, cum_var_explained, layout=(1,2), size=(800,400))"
      ],
      "id": "1428e63f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.3 Transform PCs\n"
      ],
      "id": "cfca7fa4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#transform temp_train onto PCA space\n",
        "temp_train_transform = transform(pca_model, temp_train_proc)\n",
        "#predict temp_test \n",
        "temp_test_transform = predict(pca_model, temp_test_proc)"
      ],
      "id": "16ea07d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.4 Save first three PCs\n"
      ],
      "id": "4dbdb358"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "PC1 = temp_train_transform[1,:]\n",
        "PC2 = temp_train_transform[2,:]\n",
        "PC3 = temp_train_transform[3,:]"
      ],
      "id": "15bc2554",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.5 Plot PCA\n",
        "\n",
        "3.5.1 Plot time series of first three PCs\n"
      ],
      "id": "d7d8a49b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pc1_plot = scatter(time_train, PC1, label=\"PC1\", xlabel=\"Time\", ylabel=\"PC1\", title=\"PC1 Time Series\", legend=:topleft)\n",
        "pc2_plot = scatter(time_train, PC2, label=\"PC2\", xlabel=\"Time\", ylabel=\"PC2\", title=\"PC2 Time Series\", legend=:topleft)\n",
        "pc3_plot = scatter(time_train, PC3, label=\"PC3\", xlabel=\"Time\", ylabel=\"PC3\", title=\"PC3 Time Series\", legend=:topleft)"
      ],
      "id": "60e02858",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.5.2 Plot first 2 PCs and mean precipitation\n"
      ],
      "id": "2c605e67"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#plot the first two PCs with the mean precipitation\n",
        "#replace missing with 0.0\n",
        "precip_train_zero = coalesce.(precip_train_reshape, 0.0)\n",
        "replace!(precip_train_zero, NaN => 0.0)\n",
        "mean_precip = mean.(precip_train_zero)\n",
        "\n",
        "pc_heat = scatter(PC1, PC2, zcolor=mean_precip'; xlabel=\"PC1\", ylabel=\"PC2\", title=\"PC1 vs PC2\", legend=:topleft)"
      ],
      "id": "ae0204c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.5.3 Plot the second and third PCs with mean precipitation\n"
      ],
      "id": "a5037235"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pc_heat = scatter(PC2, PC3, zcolor=mean_precip'; xlabel=\"PC1\", ylabel=\"PC2\", title=\"PC2 vs PC3\", legend=:topleft)"
      ],
      "id": "1836ae41",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Approach 1: KNN\n",
        "\t\n",
        "Given the high dimensional structure of the gridded temperature data, a principal components analysis was performed to downscale the features while preserving variation to allow for modeling across space and time. PCA effectively reduces the number of columns (in this case, locations) by projecting the data onto new PC axes. The number of principal components to retain was determined by plotting the variance explained by the principal components and the cumulative variance. After analyzing these figures, a break in variance is observed after principal component number two. The cumulative variance explained plot reveals that approximately 97.8% of the variance is explained by the first three principal components, so three principal components were retained for further analysis. The PCA model was fit to the training temperature data and then the temperature training and testing data were transformed onto the PCA space.\n",
        "\n",
        "KNN was then used to predict the precipitation data for the testing temperature data given temperature and precipitation over the training period.The KNN function calculates the Euclidean distance between the new datapoint and the existing K data points and assigns weights based on these distances. Weighted sampling is then conducted to obtain the predicted value based on the indexed position sampled. Three was chosen as the hyperparameter for the number of neighbors because this number of neighbors is standard in KNN analysis and serves as an appropriate baseline. The resultant predicted precipitation values were compared to the actual precipitation training data to evaluate the fit of the model using residuals, MAE, and MSE.\n",
        "\n",
        "\n",
        "4.1 Define KNN function\n"
      ],
      "id": "eb6234b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#source: lab 6\n",
        "#define euclidean distance function\n",
        "function euclidean_distance(x::AbstractVector, y::AbstractVector)::AbstractFloat\n",
        "return sqrt(sum((x .- y) .^ 2))\n",
        "end\n",
        "\n",
        "#define nsmallest function\n",
        "function nsmallest(x::AbstractVector, n::Int)::Vector{Int}\n",
        "idx = sortperm(x)\n",
        "return idx[1:n]\n",
        "end\n",
        "\n",
        "#define knn function\n",
        "function knn(X::AbstractMatrix, X_i::AbstractVector, K::Int)::Tuple{Int,AbstractVector}\n",
        "# calculate the distances between X_i and each row of X\n",
        "dist = [euclidean_distance(X_i, X[j, :]) for j in 1:size(X, 1)]\n",
        "idx = nsmallest(dist, K)\n",
        "w = 1 ./ dist[idx]\n",
        "w ./= sum(w)\n",
        "idx_sample = sample(idx, Weights(w))\n",
        "return (idx_sample, vec(X[idx_sample, :]))\n",
        "end"
      ],
      "id": "4c449213",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.2 Combining PCA and KNN\n"
      ],
      "id": "01d7be92"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#source: lab 6\n",
        "function predict_knn(\n",
        "                  temp_train::Array{Union{Missing, Float64}, 3}, \n",
        "                  temp_test::Array{Union{Missing, Float64}, 3}, \n",
        "                  precip_train::Array{AbstractFloat, 3},\n",
        "                  n_pca::Int64, \n",
        "                  K::Int64)\n",
        "    #preprocessing\n",
        "        temp_train_proc = preprocess(temp_train, temp_train) \n",
        "        temp_test_proc = preprocess(temp_test, temp_test) \n",
        "    #dimensionality reduction using PCA\n",
        "        #apply PCA to test\n",
        "        pca_model = fit(PCA, temp_train_proc; maxoutdim=n_pca)\n",
        "        #predict test data onto PCA\n",
        "        predict_train = predict(pca_model, temp_train_proc)\n",
        "        predict_test = predict(pca_model, temp_test_proc)\n",
        "              \n",
        "    # use the `knn` function for each point in the test data\n",
        "        predicted_precip = map(1:size(temp_test_proc, 2)) do i\n",
        "        #find the indices of the n smallest values in x\n",
        "        #K = number of nearest neighbors\n",
        "        index, _ = knn(predict_train', predict_test[:,i], K)\n",
        "                      precip_train[:,:, index]\n",
        "         end\n",
        "                 \n",
        "   \n",
        "    return predicted_precip\n",
        "end"
      ],
      "id": "38a3bdfd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.3 Test the model\n"
      ],
      "id": "31c0aa84"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#replace missing with 0.0\n",
        "precip_train_zero = coalesce.(precip_train, 0.0)\n",
        "#predict test precipitation \n",
        "pca_knn_test_predict = predict_knn(temp_train, temp_test, precip_train_zero, 3, 3 )\n",
        "#convert vector of matrices to 3D array\n",
        "pca_knn_test_predict_reshape = cat(pca_knn_test_predict..., dims=3)"
      ],
      "id": "2acff36d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.4 Analyze Fit\n",
        "\n",
        "4.4.1 Reshape data for plotting\n"
      ],
      "id": "d8c7252d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#replace missing with 0.0\n",
        "precip_test_zero = coalesce.(precip_test, 0.0)\n",
        "\n",
        "#rehape to 2D array\n",
        "precip_test_reshape = reshape(precip_test_zero, (24*24, 731))\n",
        "pca_knn_test_predict_2D = reshape(pca_knn_test_predict_reshape, (24*24, 731))"
      ],
      "id": "87f00f6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.4.2 Time series actual vs predicted test precipitation\n"
      ],
      "id": "8620fe77"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#plot predicted precipitation vs actual precipitation at a single grid cell\n",
        "plot(time_test[1:731], pca_knn_test_predict_2D[1, :], label=\"Actual Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", title=\"Precipitation at t+1 Predicted by KNN- GC 1\", legend=:topleft)\n",
        "plot!(time_test[1:731], precip_test_reshape[1,:], label=\"Predicted Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", legend=:topleft)"
      ],
      "id": "74349ca8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#plot predicted precipitation vs actual precipitation at a single grid cell\n",
        "plot(time_test[1:731], pca_knn_test_predict_2D[150, :], label=\"Actual Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", title=\"Precipitation at t+1 Predicted by KNN- GC 150\", legend=:topleft)\n",
        "plot!(time_test[1:731], precip_test_reshape[150,:], label=\"Predicted Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", legend=:topleft)"
      ],
      "id": "c02a83cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#plot predicted precipitation vs actual precipitation at a single grid cell\n",
        "plot(time_test[1:731], pca_knn_test_predict_2D[400, :], label=\"Actual Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", title=\"Precipitation at t+1 Predicted by KNN- GC 400\", legend=:topleft)\n",
        "plot!(time_test[1:731], precip_test_reshape[400,:], label=\"Predicted Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", legend=:topleft)"
      ],
      "id": "bceb8e3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.4.3 Heatmaps\n"
      ],
      "id": "2823eb5c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Plot for several time points at all grid cells\n",
        "knn_pred_hm_1 = heatmap(pca_knn_test_predict_reshape[:,:,1]; xlabel=\"Longitude\", ylabel=\"Latitude\", title=\"Predicted Precipitation at t+1 Predicted by KNN\", legend=:topleft)\n",
        "\n",
        "knn_act_hm_1 = heatmap( precip_test_zero[:, :, 1]; label=\"Actual Precipitation\", xlabel=\"Longitude\", ylabel=\"Latitude\", title=\"Actual Precipitation at t+1 Predicted by KNN\", legend=:topleft)\n",
        "\n",
        "knn_pred_hm_150 = heatmap(pca_knn_test_predict_reshape[:,:,150]; xlabel=\"Longitude\", ylabel=\"Latitude\", title=\"Predicted Precipitation at t+1 Predicted by KNN\", legend=:topleft)\n",
        "\n",
        "\n",
        "knn_act_hm_150 = heatmap( precip_test_zero[:, :, 150]; label=\"Actual Precipitation\", xlabel=\"Longitude\", ylabel=\"Latitude\", title=\"Actual Precipitation at t+1 Predicted by KNN\", legend=:topleft)\n",
        "\n",
        "knn_pred_hm_400 = heatmap(pca_knn_test_predict_reshape[:,:,400]; xlabel=\"Longitude\", ylabel=\"Latitude\", title=\"Predicted Precipitation at t+1 Predicted by KNN\", legend=:topleft)\n",
        "\n",
        "\n",
        "knn_act_hm_400 = heatmap( precip_test_zero[:, :, 400]; label=\"Actual Precipitation\", xlabel=\"Longitude\", ylabel=\"Latitude\", title=\"Actual Precipitation at t+1 Predicted by KNN\", legend=:topleft)"
      ],
      "id": "314779c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.4.4 Evaluate fit using MSE\n"
      ],
      "id": "de373868"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Define mse function\n",
        "function mean_se(x::AbstractVector, y::AbstractVector)::AbstractFloat\n",
        "return mean((x .- y) .^ 2)\n",
        "end"
      ],
      "id": "f99883b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate mse for each point in precip_test\n",
        "#create an empty vector\n",
        "mse_knn = []\n",
        "for i in 1:size(precip_test_zero, 1)\n",
        "    mse_ = mean_se(pca_knn_test_predict_2D[:,i], precip_test_zero[:,i])\n",
        "    #store mse in vector\n",
        "    push!(mse_knn, mse_)\n",
        "end"
      ],
      "id": "4c2b38bb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.4.5 Evaluate fit using MAE\n"
      ],
      "id": "35b65a35"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Define mae function\n",
        "function mean_abs_error(x::AbstractVector, y::AbstractVector)::AbstractFloat\n",
        "return mean(abs.(x .- y))\n",
        "end"
      ],
      "id": "f86b8f97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#create empty vector\n",
        "mae_knn = []\n",
        "for i in 1:size(precip_test_zero, 1)\n",
        "    mae_ = mean_abs_error(pca_knn_test_predict_2D[:,i], precip_test_zero[:,i])\n",
        "    #store mae in vector\n",
        "    push!(mae_knn, mae_)\n",
        "end"
      ],
      "id": "da6f8018",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.4.6 Evaluate fit using residuals\n"
      ],
      "id": "bb6e0d3f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Define residuals function\n",
        "function residuals(x::AbstractVector, y::AbstractVector)::AbstractVector\n",
        "return x .- y\n",
        "end"
      ],
      "id": "d667bad1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#create vector for residuals\n",
        "residuals_knn = Vector{Float32}(undef, size(precip_test_zero, 1) * size(precip_test_zero, 2))\n",
        "\n",
        "k = 1\n",
        "for i in 1:size(precip_test_zero, 1)\n",
        "    for j in 1:size(precip_test_zero, 2)\n",
        "        residuals_knn[k] = pca_knn_test_predict_2D[i, j] - precip_test_zero[i, j]\n",
        "        k += 1\n",
        "    end\n",
        "end"
      ],
      "id": "ae5d4281",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Approach 2: PCA/Linear Regression\n",
        "\n",
        "Similarly to Approach 1, Approach 2 employed PCA to reduce the dimensions of the temperature data. Only the first principal component was retained for further linear regression to allow for the creation of simple vectors that are compatible with linear regression syntax. Linear regression was performed on precipitation at each grid cell location following the first principal component of the temperature data. The temperature test data was then applied to this linear model to predict precipitation and was similarly compared to actual observed precipitation to evaluate the model using residuals, MAE, and MSE.\n",
        "\n",
        "5.1 Linear Regression\n"
      ],
      "id": "e88cd8ca"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#fit the PCA model to training data and transform the temp train and testing data onto the PCA space\n",
        "pca_model = fit(PCA, temp_train_proc; maxoutdim=1)\n",
        "                  #predict test data onto PCA\n",
        "                  predict_train = predict(pca_model, temp_train_proc)\n",
        "                  predict_test = predict(pca_model, temp_test_proc)\n",
        "\n",
        "#transpose predict_train and predict_test\n",
        "temp_train_transform = predict_train'\n",
        "temp_test_transform = predict_test'\n",
        "#save as vectors\n",
        "temp_train_transform = temp_train_transform[:]\n",
        "temp_test_transform = temp_test_transform[:]\n",
        "\n",
        "#remove missing values from precip_train\n",
        "precip_train_zero = coalesce.(precip_train, 0.0)\n",
        "#reshape to lonxlat\n",
        "precip_train_reshape = reshape(precip_train_zero, (24 * 24, 2921))"
      ],
      "id": "6131cd8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#regression for all grid cells in precip_train\n",
        "# Create an empty vector to store predictions\n",
        "all_predictions = Vector{Vector{Float64}}()\n",
        "for grid_cell in 1:size(precip_train_reshape, 1)\n",
        "    precip_train_linear = convert(Vector{Float64},precip_train_reshape[grid_cell, :])\n",
        "    # Create a DataFrame for the training data\n",
        "    df = DataFrame(temp_train_transform = temp_train_transform, precip_train_linear = precip_train_linear)\n",
        "\n",
        "    # Fit linear regression model\n",
        "    linear_model = lm(@formula(precip_train_linear ~ temp_train_transform), df)\n",
        "\n",
        "    # Create a DataFrame for the test data\n",
        "    df_test = DataFrame(temp_train_transform = temp_test_transform)\n",
        "\n",
        "    # Predict precipitation for temp_test\n",
        "    y_pred = predict(linear_model, df_test)\n",
        " push!(all_predictions, y_pred)\n",
        "end\n",
        "#convert to matrix\n",
        "all_predictions_matrix = hcat(all_predictions...)"
      ],
      "id": "b10c1bf8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5.2 Analyze Fit\n",
        "5.2.1 Plot time series of actual vs predicted precipitation at different grid cells\n"
      ],
      "id": "0e9ffcfe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#plot y_pred vs test_time at different grid cells\n",
        "plot(time_test[1:731], all_predictions_matrix[:,1], label=\"Predicted Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", title=\"Linear Regression\", legend=:topleft)\n",
        "plot!(time_test[1:731], precip_test_reshape[1, :], label=\"Actual Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", title=\"Precipitation at t+1 Predicted by Lin Reg- GC 1\", legend=:topleft)"
      ],
      "id": "a2f5efce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot(time_test[1:731], all_predictions_matrix[:,150], label=\"Predicted Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", title=\"Linear Regression\", legend=:topleft)\n",
        "plot!(time_test[1:731], precip_test_reshape[150, :], label=\"Actual Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", title=\"Precipitation at t+1 Predicted by Lin Reg- GC 150\", legend=:topleft)"
      ],
      "id": "82057d24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot(time_test[1:731], all_predictions_matrix[:,400], label=\"Predicted Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", title=\"Linear Regression\", legend=:topleft)\n",
        "plot!(time_test[1:731], precip_test_reshape[400, :], label=\"Actual Precipitation\", xlabel=\"Time\", ylabel=\"Precipitation\", title=\"Precipitation at t+1 Predicted by Linear Regression- GC 400\", legend=:topleft)"
      ],
      "id": "cf98d273",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5.2.2 Evaluate Fit using MSE\n"
      ],
      "id": "050c3290"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mse_lin = []\n",
        "for i in 1:size(precip_test_reshape, 1)\n",
        "    mse_ = mean_se(all_predictions_matrix[i,:], precip_test_reshape[:,i])\n",
        "    push!(mse_lin, mse_)\n",
        "end"
      ],
      "id": "44c746f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5.2.3 Evaluate fit using MAE\n"
      ],
      "id": "9a34ca86"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mae_lin = []\n",
        "for i in 1:size(precip_test_reshape, 1)\n",
        "    mae_ = mean_abs_error(all_predictions_matrix[i,:], precip_test_reshape[:,i])\n",
        "    push!(mae_lin, mae_)\n",
        "end"
      ],
      "id": "2ac0e940",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5.2.4 Evaluate fit using residuals\n"
      ],
      "id": "289b0937"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "residuals_lin = Vector{Float32}(undef, size(precip_test_reshape, 1) * size(precip_test_zero, 2))\n",
        "\n",
        "k = 1\n",
        "for i in 1:size(precip_test_reshape, 1)\n",
        "    for j in 1:size(precip_test_reshape, 2)\n",
        "        residuals_lin[k] = all_predictions_matrix[j, i] - precip_test_reshape[i,j ]\n",
        "        k += 1\n",
        "    end\n",
        "end"
      ],
      "id": "042e7f50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Compare\n",
        "\n",
        "When plotting the predicted precipitation and the actual precipitation for the test data, upon visual inspection it seems that the PCA-KNN model more closely resembles the trends of the actual precipitation. The PCA-KNN predicted precipitation of varying levels while the PCA-linear regression model predicted nearly constant, low-level precipitation year-round, with some reflection of the seasonal trends as the maximum periods of the curves occur over the same range of time. However, upon closer analysis, the PCA-KNN model predictions differed significantly from the actual precipitation values. When considering only the residuals of actual precipitation minus predicted precipitation, the PCA-KNN model appears to perform better because the average of the residuals is lower than the PCA-linear regression model. However, when considering the mean absolute error and the mean squared error, the PCA-linear regression model outperformed the PCA-KNN model with significantly lower MAE and MSE, indicating overall that predictions are closer to actual values than the PCA-KNN model. Residuals might be lower than MSE or MAE for a model if there are both undershoots and overshoots when considering the entire dataset of predictions. For example, if the PCA-KNN model predicted 0 mm on a day that should be 40 mm and 40 mm on a day that should be 0 mm, the averaged residuals would be zero since they cancel out. MSE and MAE, however, are a more robust measure of model performance because they account for differences in sign via squaring and absolute value respectively. MSE places a greater emphasis on large errors but is sensitive to outliers, which explains why the difference in MSE is greater between the two models than MAE. \n",
        "\n",
        "The PCA-KNN model appears to be capturing the general shape of the data better, but local predictions are not very reliable based on the MAE and MSE calculations. This model could be further optimized by optimizing the hyperparameters n_pca and K. N_pca is the number of principal components retained in the model. Three was selected as the n_pca value in this analysis based on fraction of variance explained, but a systematic approach could be taken to test all values of PCs and retain the number with the lowest MSE/MAE. A similar systematic approach could be used to optimize the K parameter as well. \n",
        "\n",
        "The PCA-linear regression model is demonstrating a “dreary” effect by predicting low level precipitation across the time series. While there are periods of slight increase and decrease over the year corresponding to seasonal variation, this model generally does not capture the shape of the data or minimum/maximum values well. Only the first principal component was retained for simplicity of the model, but to improve the predictions more principal components should be considered. Additional principal components may more accurately capture heavy precipitation patterns and predict values closer to actual precipitation on heavy rainfall days.\n",
        "\n",
        "A limitation of both models is the handling of missing precipitation values. This analysis elected to replace missing values with 0.0, but this is likely altering predictive accuracy by introducing bias. An improvement would be to remove missing values altogether before conducting data analysis. Another major limitation of both models is only using temperature data to predict precipitation. Based on prior knowledge, pressure data is also important in predicting precipitation and model performance likely would have significantly included if more variables beyond temperature were included.\n"
      ],
      "id": "21b9e44c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mae_lin_mean = mean(mae_lin)\n",
        "mae_knn_mean = mean(mae_knn) \n",
        "mse_knn_mean = mean(mse_knn)\n",
        "mse_lin_mean = mean(mse_lin)\n",
        "residuals_lin_mean = mean(residuals_lin)\n",
        "residuals_knn_mean = mean(residuals_knn)"
      ],
      "id": "5ab5cf0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#create bar chart mae\n",
        "bar([\"Linear Regression\", \"KNN\"], [mae_lin_mean, mae_knn_mean], label=\"MAE\", title=\"MAE for Linear Regression and KNN\", xlabel=\"Model\", ylabel=\"MAE\", legend=:topleft)"
      ],
      "id": "67a005f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#create bar chart mse\n",
        "bar([\"Linear Regression\", \"KNN\"], [mse_lin_mean, mse_knn_mean], label=\"MSE\", title=\"MSE for Linear Regression and KNN\", xlabel=\"Model\", ylabel=\"MSE\", legend=:topleft)"
      ],
      "id": "eef895d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#create bar chart residuals\n",
        "bar([\"Linear Regression\", \"KNN\"], [residuals_lin_mean, residuals_knn_mean], label=\"Residuals\", title=\"Residuals for Linear Regression and KNN\", xlabel=\"Model\", ylabel=\"Residuals\", legend=:topleft)"
      ],
      "id": "182a4a47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Conclusion\n",
        "\n",
        "This report provides preliminary models to predict precipitation at time t+1 based on temperature at time t over Texas. Both approaches employ a principal component analysis to downscale high dimensional spatial data while retaining variance explained within the data. Approach 1 then applies K-nearest neighbors to predict precipitation using weighted sampling indexes of the three closest neighbors. After PCA, Approach 2 applies a linear regression to the first principal component at each grid cell of precipitation following temperature. When comparing predicted and actual precipitation across the two models, Approach 1 appears to capture the range of precipitation values more accurately but exhibits a higher mean squared error and mean absolute error, indicating poorer overall model performance. Approach 2 predicts low level precipitation across the entire time series and thus has lower mean squared error and mean absolute error values due to a lack of appropriate extremes.\n",
        "\n",
        "If the goal of the model prediction was to minimize MSE and MAE, then Approach 2 would be a better model. Both models would be significantly improved by the optimization of chosen model parameters and the inclusion of additional climate variables, including pressure, to predict precipitation. "
      ],
      "id": "a7440162"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.9",
      "language": "julia",
      "display_name": "Julia 1.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}