---
title: "Precipitation Downscaling Project"
jupyter: julia-1.9
date: 2023-11-2
author: "Lily Metsker (lm88)" 
echo: false

number-sections: true
code-annotations: hover

kind: "Project"
Module: "2"
categories:
    - "Module 2"
    - "Project"

format:
    html: 
    toc-depth: 3
    docx: 
        toc: true
        toc-depth: 3
        fig-format: png
---

1. Setup

1.1 Load Packages
```{julia}
using Dates
using MultivariateStats
using Plots
using NCDatasets
using StatsBase
using Unitful
using Distances
using GLM
using NetCDF
using DataFrames
```

2. Data

2.1 Precipitation
2.1.1 Load data
```{julia}
#load precip data from NCDataset, this precip is over the area of Texas
precip_ds = NCDataset("data/raw/precip_tx.nc")
#define time, longitude, latitude, and precip as variables. precip is a matrix and time, lon, and lat are vectors
precip_time = precip_ds["time"][:]
precip_lon = precip_ds["lon"][:]
precip_lat = precip_ds["lat"][:]
precip = precip_ds["precip"][:,:,:]
```

2.1.2 Close precip dataset
```{julia}
close(precip_ds) 
```

2.1.3 Filter data
```{julia}
#filter precip to only include 2000-2009
t_start = 2000
t_end = 2009

start_ind = findfirst(date -> year(date) >= t_start, precip_time)
end_ind = findlast(date -> year(date) <= t_end, precip_time)
precip = precip[:,:, start_ind:end_ind]
precip_time = precip_time[start_ind:end_ind]
```

2.1.4 Subset data
```{julia}
#subset precip to time range t+1
t_start = Dates.DateTime(2000, 1, 2)
t_end = Dates.DateTime(2009, 12, 31)

#create index for filtering 

precip_indices = t_start .<= precip_time .<= t_end

precip = precip[:, :, precip_indices]
precip_time_plus = precip_time[precip_indices]
```


2.1.5 Reverse latitude
```{julia}
#dims 2 is telling to reverse along the second dimension (latitude)
precip_lat = reverse(precip_lat)
precip = reverse(precip;dims=2)
```

2.1.6 Convert lon to lon1 format
```{julia}
#Convert long3 to long1 format (source: https://confluence.ecmwf.int/pages/viewpage.action?pageId=149337515)
function convert_longitude(longitude)
    lon1 = ifelse(longitude > 180, longitude - 360, longitude)
    return lon1
end

precip_lon = convert_longitude.(precip_lon)
```


2.2 Temperature

2.2.1 Load data
#(move to get_data.jl file)?
```{julia}
#This code block was written by Chatgpt to resample hourly temperature data to daily temperature data

# Write a function to convert hourly temperature to daily average
function resample_to_daily_average(temp, temp_time)

    #use floor to extract the date from the time, save as date_vector
    date_vector = floor.(temp_time, Dates.Day)
    #find all unique dates in the date_vector, save as unique_dates
    unique_dates = unique(date_vector)

    # Find the size of the temperature array, save as lon_points and lat_points
    lon_points, lat_points, _ = size(temp)

    # Create an empty array to store daily temperature averages
    daily_temps = []

    # Calculate daily mean by grouping unique dates
    for date in unique_dates
        # Find indices of all time points under a unique date
        indices = findall(date_vector .== date)
        
        # Calculate daily mean for each lonxlat point
        daily_mean = mean(temp[:, :, indices], dims=3)[:, :, 1]
        
        # Add daily mean to the empty array
        push!(daily_temps, daily_mean)
    end

    # Concatenate daily means into a 3D array along the 3rd dimension
    daily_temps = cat(daily_temps..., dims=3)

    return daily_temps
end

#Write a function to call and process each year of temperature data
function process_year(data_path)
    # Extract year from filename, all files follow a common path structure
    match_result = match(r"2m_temperature_(\d{4})\.nc", data_path)
    #save individual years as string
    year_str = match_result.captures[1]
    #save as variable of integers
    year = parse(Int, year_str)

    # Load year's data, all files follow common data_path
    temp_dataset = NCDataset(data_path)

    # Save lon, lat, time, and temperature as variables
    longitude = temp_dataset["longitude"][:]
    latitude = temp_dataset["latitude"][:]
    time = temp_dataset["time"][:]
    t2m = temp_dataset["t2m"][:, :, :]

    #save time as temp_time
    temp_time = time

    # Resample temperature data to daily averages
    daily_temps_result = resample_to_daily_average(t2m, temp_time)

    return year, daily_temps_result
end

# Paths to your data files for each year
data_paths = [
    "data/raw/2m_temperature_2000.nc",
    "data/raw/2m_temperature_2001.nc",
    "data/raw/2m_temperature_2002.nc",
    "data/raw/2m_temperature_2003.nc",
    "data/raw/2m_temperature_2004.nc",
    "data/raw/2m_temperature_2005.nc",
    "data/raw/2m_temperature_2006.nc",
    "data/raw/2m_temperature_2007.nc",
    "data/raw/2m_temperature_2008.nc",
    "data/raw/2m_temperature_2009.nc"
]

# Process each year and combine the results
all_years_temps = Dict(process_year(path) for path in data_paths if process_year(path) !== nothing)
```


2.2.2 Combine
```{julia}
#combine all years into one array
#call all years and save each as a matrix with lon = 66, lat = 27, and time in days, 365 for non-leap years and 366 for leap years
temp_2000 = reshape(all_years_temps[2000], 66, 27, 366)
temp_2001 = reshape(all_years_temps[2001], 66, 27, 365)
temp_2002 = reshape(all_years_temps[2002], 66, 27, 365)
temp_2003 = reshape(all_years_temps[2003], 66, 27, 365)
temp_2004 = reshape(all_years_temps[2004], 66, 27, 366)
temp_2005 = reshape(all_years_temps[2005], 66, 27, 365)
temp_2006 = reshape(all_years_temps[2006], 66, 27, 365)
temp_2007 = reshape(all_years_temps[2007], 66, 27, 365)
temp_2008 = reshape(all_years_temps[2008], 66, 27, 366)
temp_2009 = reshape(all_years_temps[2009], 66, 27, 365)

#combine 
temp = cat(temp_2000, temp_2001, temp_2002, temp_2003, temp_2004, temp_2005, temp_2006, temp_2007, temp_2008, temp_2009, dims=3)
```

2.2.3 Save lon, lat, time, and temp variables
```{julia}
#Having trouble writing variable using same form of calling above, used data_dict instead but not optimal

#save data_dict for 2000
data_dict = open_mfdataset(["data/raw/2m_temperature_2000.nc"], "t2m")

#define lon and lat based on year 2000 (should be the same for all years) and temp_time as precip_time (should be the same)
temp_lon = data_dict["longitude"][:]
temp_lat = data_dict["latitude"][:]
temp_time = precip_time

```

2.2.4 Flip the temperature latitude
```{julia}
temp_lat = reverse(temp_lat)
temp = reverse(temp;dims=2)
```

2.2.5 Subset temperature to area of Texas instead of US
```{julia}
# Define longitude and latitude ranges for filtering based on precip data which is already filtered to Texas
lon_min = minimum(precip_lon)
lon_max = maximum(precip_lon)
lat_min = minimum(precip_lat)
lat_max = maximum(precip_lat)

# Create masks for latitude and longitude based on specified ranges
lat_mask = (lat_min .<= temp_lat .<= lat_max)
lon_mask = (lon_min .<= temp_lon .<= lon_max)

# Convert BitVector to Vector{Int} using findall
lat_indices = findall(lat_mask)
lon_indices = findall(lon_mask)

# Update latitude and longitude data variables
temp_lat = temp_lat[lat_indices]
temp_lon = temp_lon[lon_indices]

# Subset temperature data based on latitude and longitude indices
temp = temp[lon_indices, lat_indices, :]
```

2.2.6 Subset temperature time
```{julia}
#subset temperature to time range t 
t_start = Dates.DateTime(2000, 1, 1)
t_end = Dates.DateTime(2009, 12, 30)

#Create index for filtering
temp_indices = t_start .<= temp_time .<= t_end

temp = temp[:, :, temp_indices]

temp_time = temp_time[temp_indices]
```


2.3 Split data into training and testing sets
```{julia}
#2000-2007 for training, 2008-2009 for testing
#Define start and end times
temp_t_start = Dates.DateTime(2000, 1, 1)
temp_t_end = Dates.DateTime(2007, 12, 30)

# Create indices for temperature
temp_train_indices = temp_t_start .<= temp_time .<= temp_t_end
temp_test_indices = temp_time .> temp_t_end

#Subset temperature data based on indices
temp_train = temp[:, :, temp_train_indices]
temp_test = temp[:, :, temp_test_indices]

#Subset temperature time based on indices
time_train = filter(date -> temp_t_start <= date <= temp_t_end, temp_time)
time_test = filter(date -> temp_t_end <= date , temp_time)

#Create indices for precipitation
precip_t_start = Dates.DateTime(2000, 1, 2)
precip_t_end = Dates.DateTime(2007, 12, 31)

#Subset precipitation data based on indices
precip_train_indices = precip_t_start .<= precip_time_plus .<= precip_t_end
precip_test_indices = precip_time_plus .> precip_t_end

#Subset precipitation data based on indices
precip_train = precip[:, :, precip_train_indices]
precip_test = precip[:, :, precip_test_indices]


```


2.4 Preprocessing

2.4.1 Preprocess function
```{julia}
function preprocess(temp::Array{T, 3}, temp_ref::Array{T,3}) where T
  #we use temp_ref because we want the climatology to be the same between the test and train datasets!
           #name lon, lat, and time as the dimensions of the temp input matrix
           lon, lat, time = size(temp)
           #find the climatology, dims=3 says take along the 3rd dimension (time)
           climatology = mean(temp_ref, dims=3)
           temp_anom = temp .- climatology
           #reshape the data by multiplying lonxlat to a 2D matrix
           temp_anom = reshape(temp_anom, (lon * lat, time))
           #return
           return temp_anom
       end

```

2.4.2 Preprocess temperature
```{julia}
temp_train_proc = preprocess(temp_train, temp_train)
temp_test_proc = preprocess(temp_test, temp_train)
```

2.4.3 Reshape precip
```{julia}
#reshape precip_train and precip_test to 2D matrices
precip_train_reshape = reshape(precip_train, (24 * 24, 2921))
precip_test_reshape = reshape(precip_test, (24 * 24, 731))
```

3. Principal Component Analysis
3.1 Fit PCA model
```{julia}
pca_model = fit(PCA, temp_train_proc; maxoutdim=25);
```

3.2 Plot variance to determine number of PCs to keep
```{julia}
#plot the variance explained
var_explained = plot(
    principalvars(pca_model) / var(pca_model),
    xlabel="PC",
    ylabel="Fraction of variance explained",
    label=false,
    title="Variance Explained by PCs"
)
#plot the cumulative variance explained (cdf)
cum_var_explained = plot(
    cumsum(principalvars(pca_model)) / var(pca_model);
    xlabel="PC",
    ylabel="Fraction of variance explained",
    label=false,
    title="Cumulative Variance Explained"
)
#Plot 
plot(var_explained, cum_var_explained, layout=(1,2), size=(800,400))
```

3.3 Transform PCs
```{julia}
#transform temp_train onto PCA space
temp_train_transform = transform(pca_model, temp_train_proc)
#predict temp_test 
temp_test_transform = predict(pca_model, temp_test_proc)
```

3.4 Save first three PCs
```{julia}
PC1 = temp_train_transform[1,:]
PC2 = temp_train_transform[2,:]
PC3 = temp_train_transform[3,:]
```

3.5 Plot PCA

3.5.1 Plot time series of first three PCs
```{julia}

pc1_plot = scatter(time_train, PC1, label="PC1", xlabel="Time", ylabel="PC1", title="PC1 Time Series", legend=:topleft)
pc2_plot = scatter(time_train, PC2, label="PC2", xlabel="Time", ylabel="PC2", title="PC2 Time Series", legend=:topleft)
pc3_plot = scatter(time_train, PC3, label="PC3", xlabel="Time", ylabel="PC3", title="PC3 Time Series", legend=:topleft)
```

3.5.2 Plot first 2 PCs and mean precipitation
```{julia}
#plot the first two PCs with the mean precipitation
#replace missing with 0.0
precip_train_zero = coalesce.(precip_train_reshape, 0.0)
replace!(precip_train_zero, NaN => 0.0)
mean_precip = mean.(precip_train_zero)

pc_heat = scatter(PC1, PC2, zcolor=mean_precip'; xlabel="PC1", ylabel="PC2", title="PC1 vs PC2", legend=:topleft)
```

3.5.3 Plot the second and third PCs with mean precipitation
```{julia}
pc_heat = scatter(PC2, PC3, zcolor=mean_precip'; xlabel="PC1", ylabel="PC2", title="PC2 vs PC3", legend=:topleft)
```


4. Approach 1: KNN

4.1 Define KNN function
```{julia}
#source: lab 6
#define euclidean distance function
function euclidean_distance(x::AbstractVector, y::AbstractVector)::AbstractFloat
return sqrt(sum((x .- y) .^ 2))
end

#define nsmallest function
function nsmallest(x::AbstractVector, n::Int)::Vector{Int}
idx = sortperm(x)
return idx[1:n]
end

#define knn function
function knn(X::AbstractMatrix, X_i::AbstractVector, K::Int)::Tuple{Int,AbstractVector}
# calculate the distances between X_i and each row of X
dist = [euclidean_distance(X_i, X[j, :]) for j in 1:size(X, 1)]
idx = nsmallest(dist, K)
w = 1 ./ dist[idx]
w ./= sum(w)
idx_sample = sample(idx, Weights(w))
return (idx_sample, vec(X[idx_sample, :]))
end
```

4.2 Combining PCA and KNN

```{julia}
#source: lab 6
function predict_knn(
                  temp_train::Array{Union{Missing, Float64}, 3}, 
                  temp_test::Array{Union{Missing, Float64}, 3}, 
                  precip_train::Array{AbstractFloat, 3},
                  n_pca::Int64, 
                  K::Int64)
    #preprocessing
        temp_train_proc = preprocess(temp_train, temp_train) 
        temp_test_proc = preprocess(temp_test, temp_test) 
    #dimensionality reduction using PCA
        #apply PCA to test
        pca_model = fit(PCA, temp_train_proc; maxoutdim=n_pca)
        #predict test data onto PCA
        predict_train = predict(pca_model, temp_train_proc)
        predict_test = predict(pca_model, temp_test_proc)
              
    # use the `knn` function for each point in the test data
        predicted_precip = map(1:size(temp_test_proc, 2)) do i
        #find the indices of the n smallest values in x
        #K = number of nearest neighbors
        index, _ = knn(predict_train', predict_test[:,i], K)
                      precip_train[:,:, index]
         end
                 
   
    return predicted_precip
end
```

4.3 Test the model
```{julia}
#replace missing with 0.0
precip_train_zero = coalesce.(precip_train, 0.0)
#predict test precipitation 
pca_knn_test_predict = predict_knn(temp_train, temp_test, precip_train_zero, 3, 3 )
#convert vector of matrices to 3D array
pca_knn_test_predict_reshape = cat(pca_knn_test_predict..., dims=3)
```


4.4 Analyze Fit

4.4.1 Reshape data for plotting
```{julia}
#replace missing with 0.0
precip_test_zero = coalesce.(precip_test, 0.0)

#rehape to 2D array
precip_test_reshape = reshape(precip_test_zero, (24*24, 731))
pca_knn_test_predict_2D = reshape(pca_knn_test_predict_reshape, (24*24, 731))
```

4.4.2 Time series actual vs predicted test precipitation
```{julia}
#plot predicted precipitation vs actual precipitation at a single grid cell
plot(time_test[1:731], pca_knn_test_predict_2D[1, :], label="Actual Precipitation", xlabel="Time", ylabel="Precipitation", title="Precipitation at t+1 Predicted by KNN- GC 1", legend=:topleft)
plot!(time_test[1:731], precip_test_reshape[1,:], label="Predicted Precipitation", xlabel="Time", ylabel="Precipitation", legend=:topleft)
```
```{julia}
#plot predicted precipitation vs actual precipitation at a single grid cell
plot(time_test[1:731], pca_knn_test_predict_2D[150, :], label="Actual Precipitation", xlabel="Time", ylabel="Precipitation", title="Precipitation at t+1 Predicted by KNN- GC 150", legend=:topleft)
plot!(time_test[1:731], precip_test_reshape[150,:], label="Predicted Precipitation", xlabel="Time", ylabel="Precipitation", legend=:topleft)
```
```{julia}
#plot predicted precipitation vs actual precipitation at a single grid cell
plot(time_test[1:731], pca_knn_test_predict_2D[400, :], label="Actual Precipitation", xlabel="Time", ylabel="Precipitation", title="Precipitation at t+1 Predicted by KNN- GC 400", legend=:topleft)
plot!(time_test[1:731], precip_test_reshape[400,:], label="Predicted Precipitation", xlabel="Time", ylabel="Precipitation", legend=:topleft)
```
4.4.3 Heatmaps
```{julia}
#Plot for several time points at all grid cells
knn_pred_hm_1 = heatmap(pca_knn_test_predict_reshape[:,:,1]; xlabel="Longitude", ylabel="Latitude", title="Predicted Precipitation at t+1 Predicted by KNN", legend=:topleft)

knn_act_hm_1 = heatmap( precip_test_zero[:, :, 1]; label="Actual Precipitation", xlabel="Longitude", ylabel="Latitude", title="Actual Precipitation at t+1 Predicted by KNN", legend=:topleft)

knn_pred_hm_150 = heatmap(pca_knn_test_predict_reshape[:,:,150]; xlabel="Longitude", ylabel="Latitude", title="Predicted Precipitation at t+1 Predicted by KNN", legend=:topleft)


knn_act_hm_150 = heatmap( precip_test_zero[:, :, 150]; label="Actual Precipitation", xlabel="Longitude", ylabel="Latitude", title="Actual Precipitation at t+1 Predicted by KNN", legend=:topleft)

knn_pred_hm_400 = heatmap(pca_knn_test_predict_reshape[:,:,400]; xlabel="Longitude", ylabel="Latitude", title="Predicted Precipitation at t+1 Predicted by KNN", legend=:topleft)


knn_act_hm_400 = heatmap( precip_test_zero[:, :, 400]; label="Actual Precipitation", xlabel="Longitude", ylabel="Latitude", title="Actual Precipitation at t+1 Predicted by KNN", legend=:topleft)

```
4.4.4 Evaluate fit using MSE
```{julia}
#Define mse function
function mean_se(x::AbstractVector, y::AbstractVector)::AbstractFloat
return mean((x .- y) .^ 2)
end
```
```{julia}
# Calculate mse for each point in precip_test
#create an empty vector
mse_knn = []
for i in 1:size(precip_test_zero, 1)
    mse_ = mean_se(pca_knn_test_predict_2D[:,i], precip_test_zero[:,i])
    #store mse in vector
    push!(mse_knn, mse_)
end
```

4.4.5 Evaluate fit using MAE
```{julia}
#Define mae function
function mean_abs_error(x::AbstractVector, y::AbstractVector)::AbstractFloat
return mean(abs.(x .- y))
end
```
```{julia}
#create empty vector
mae_knn = []
for i in 1:size(precip_test_zero, 1)
    mae_ = mean_abs_error(pca_knn_test_predict_2D[:,i], precip_test_zero[:,i])
    #store mae in vector
    push!(mae_knn, mae_)
end
```
4.4.6 Evaluate fit using residuals
```{julia}
#Define residuals function
function residuals(x::AbstractVector, y::AbstractVector)::AbstractVector
return x .- y
end
```
```{julia}
#create vector for residuals
residuals_knn = Vector{Float32}(undef, size(precip_test_zero, 1) * size(precip_test_zero, 2))

k = 1
for i in 1:size(precip_test_zero, 1)
    for j in 1:size(precip_test_zero, 2)
        residuals_knn[k] = pca_knn_test_predict_2D[i, j] - precip_test_zero[i, j]
        k += 1
    end
end

```


5. Approach 2: PCA/Linear Regression

5.1 Linear Regression
```{julia}
#fit the PCA model to training data and transform the temp train and testing data onto the PCA space
pca_model = fit(PCA, temp_train_proc; maxoutdim=1)
                  #predict test data onto PCA
                  predict_train = predict(pca_model, temp_train_proc)
                  predict_test = predict(pca_model, temp_test_proc)

#transpose predict_train and predict_test
temp_train_transform = predict_train'
temp_test_transform = predict_test'
#save as vectors
temp_train_transform = temp_train_transform[:]
temp_test_transform = temp_test_transform[:]

#remove missing values from precip_train
precip_train_zero = coalesce.(precip_train, 0.0)
#reshape to lonxlat
precip_train_reshape = reshape(precip_train_zero, (24 * 24, 2921))
```
```{julia}
#regression for all grid cells in precip_train
# Create an empty vector to store predictions
all_predictions = Vector{Vector{Float64}}()
for grid_cell in 1:size(precip_train_reshape, 1)
    precip_train_linear = convert(Vector{Float64},precip_train_reshape[grid_cell, :])
    # Create a DataFrame for the training data
    df = DataFrame(temp_train_transform = temp_train_transform, precip_train_linear = precip_train_linear)

    # Fit linear regression model
    linear_model = lm(@formula(precip_train_linear ~ temp_train_transform), df)

    # Create a DataFrame for the test data
    df_test = DataFrame(temp_train_transform = temp_test_transform)

    # Predict precipitation for temp_test
    y_pred = predict(linear_model, df_test)
 push!(all_predictions, y_pred)
end
#convert to matrix
all_predictions_matrix = hcat(all_predictions...)
```
5.2 Analyze Fit
5.2.1 Plot time series of actual vs predicted precipitation at different grid cells
```{julia}
#plot y_pred vs test_time at different grid cells
plot(time_test[1:731], all_predictions_matrix[:,1], label="Predicted Precipitation", xlabel="Time", ylabel="Precipitation", title="Linear Regression", legend=:topleft)
plot!(time_test[1:731], precip_test_reshape[1, :], label="Actual Precipitation", xlabel="Time", ylabel="Precipitation", title="Precipitation at t+1 Predicted by Linear Regression- GC 1", legend=:topleft)
```
```{julia}
plot(time_test[1:731], all_predictions_matrix[:,150], label="Predicted Precipitation", xlabel="Time", ylabel="Precipitation", title="Linear Regression", legend=:topleft)
plot!(time_test[1:731], precip_test_reshape[150, :], label="Actual Precipitation", xlabel="Time", ylabel="Precipitation", title="Precipitation at t+1 Predicted by Linear Regression- GC 150", legend=:topleft)
```
```{julia}
plot(time_test[1:731], all_predictions_matrix[:,400], label="Predicted Precipitation", xlabel="Time", ylabel="Precipitation", title="Linear Regression", legend=:topleft)
plot!(time_test[1:731], precip_test_reshape[400, :], label="Actual Precipitation", xlabel="Time", ylabel="Precipitation", title="Precipitation at t+1 Predicted by Linear Regression- GC 400", legend=:topleft)
```

5.2.2 Evaluate Fit using MSE
```{julia}
mse_lin = []
for i in 1:size(precip_test_reshape, 1)
    mse_ = mean_se(all_predictions_matrix[i,:], precip_test_reshape[:,i])
    push!(mse_lin, mse_)
end
```

5.2.3 Evaluate fit using MAE
```{julia}
mae_lin = []
for i in 1:size(precip_test_reshape, 1)
    mae_ = mean_abs_error(all_predictions_matrix[i,:], precip_test_reshape[:,i])
    push!(mae_lin, mae_)
end
```

5.2.4 Evaluate fit using residuals
```{julia}
residuals_lin = Vector{Float32}(undef, size(precip_test_reshape, 1) * size(precip_test_zero, 2))

k = 1
for i in 1:size(precip_test_reshape, 1)
    for j in 1:size(precip_test_reshape, 2)
        residuals_lin[k] = all_predictions_matrix[j, i] - precip_test_reshape[i,j ]
        k += 1
    end
end
```


6. Compare
```{julia}
mae_lin_mean = mean(mae_lin)
mae_knn_mean = mean(mae_knn) 
mse_knn_mean = mean(mse_knn)
mse_lin_mean = mean(mse_lin)
residuals_lin_mean = mean(residuals_lin)
residuals_knn_mean = mean(residuals_knn)
```

```{julia}
#create bar chart mae
bar(["Linear Regression", "KNN"], [mae_lin_mean, mae_knn_mean], label="MAE", title="MAE for Linear Regression and KNN", xlabel="Model", ylabel="MAE", legend=:topleft)
```
```{julia}
#create bar chart mse
bar(["Linear Regression", "KNN"], [mse_lin_mean, mse_knn_mean], label="MSE", title="MSE for Linear Regression and KNN", xlabel="Model", ylabel="MSE", legend=:topleft)
```
```{julia}
#create bar chart residuals
bar(["Linear Regression", "KNN"], [residuals_lin_mean, residuals_knn_mean], label="Residuals", title="Residuals for Linear Regression and KNN", xlabel="Model", ylabel="Residuals", legend=:topleft)
```
